---
title: "SQM 03 - Linear Model Basics"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
library(sqmf)
library(tidyverse)
data("mald_1_1")
data("polite")
data("dur_ita_pol")
```

## Example 1: English

### The MALD data

We will use `mald_1_1` (made available through the sqmf package), which contains data from a lexical decision task.

We want to know if phoneme-level distance (`PhonLev`, i.e. Levenshtein distance) affect the reaction times of respondents when they need to decide whether the word they heard is a real word or a nonce word.

Here's what the data looks like.

```{r mald, exercise=TRUE}
mald_1_1
```

### Phoneme-level distance vs reaction times

Let's start by plotting phoneme-level distance (`PhonLev`) vs reaction times (`RT`).

You want to use a *scatter plot*.

```{r mald-plot, exercise=TRUE}
mald_1_1 %>%
  ...
```

<div id="mald-plot-hint">
A **scatter plot** is a plot with continuous variables in the *x* and *y* axes.
</div>

### Model distance vs RTs

Now we can run a simple linear model to investigate the relationship between phoneme-level distance and reaction times.

Fill in the following code with the right formula.
Then check the model summary.

```{r mald-lm, exercise=TRUE}
lm_1 <- lm(..., data = mald_1_1)

...
```

```{r mald-lm-hint}
summary(...)
```

### Does phoneme-level distance affect reaction times?

Great! Now that you have seen the model summary, answer the following questions.

```{r Q-lm-1-1, echo=FALSE}
question(
  "Which of the following statements is correct?",
  answer('The mean RT is 771.2 ms.'),
  answer('The model intercept is 33.7 ms.'),
  answer('When distance is 33.7, the average reaction time is 771.2 ms.'),
  answer('On average, the reaction time is 771.2 ms, when distance is 0.', correct = TRUE),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

```{r Q-lm-1-2, echo=FALSE}
question(
  "The effect of `PhonLev` on `RT` is",
  answer('positive.', correct = TRUE),
  answer('negative.'),
  answer('zero.'),
  answer('3.4 ms.'),
  correct = "Correct! The sign of the effect is `+`, so the effect is positive.",
  incorrect = "Nope!"
)
```

```{r Q-lm-1-3, echo=FALSE}
question(
  "Which of the following statements is correct?",
  answer('When the intercept is 0, phoneme-level distance is 33.7.'),
  answer('For every unit increase of phoneme-level distance, there is an increase of 33.7 ms.', correct = TRUE),
  answer('When phoneme-level distance is 0, the reaction time is 33.7 ms.'),
  answer('For every 1 ms, the phoneme-level distance increases by 33.7.'),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

```{r Q-lm-1-4, echo=FALSE}
question(
  "What is the effect of phoneme-level distance when the distance is 3?",
  answer('101.1 ms.', correct = TRUE),
  answer('0 ms.'),
  answer('33.7 ms.'),
  answer('3.4 ms.'),
  correct = "Correct! To get the effect when distance is 3, you just do `33.7 * 3`.",
  incorrect = "Nope!"
)
```

## Example 2: Korean

### The politness data

Let's move now to `polite` (made available through the sqmf package), which contains data from study of the acoustics of polite speech in Korean.

Imagine we want to know, regardless of attitude (i.e. informal vs polite speech), if articulation rate (i.e. the number of syllables per second) is correlated with the mean intensity of each utterance.

Here's what the data looks like.

```{r polite, exercise=TRUE}
polite
```

### Articulation rate vs intensity

Let's make a plot of articulation rate `articulation_rate` vs intensity `inmn`.

```{r art-int-plot-1, exercise=TRUE}
polite %>%
  ggplot(aes(...)) +
  geom_point() +
  labs(x = "Articulation rate (syll/s)", y = "Mean intensity (dB)")
```

Does it look like there is something about articulation rate and intensity?

Let's further check by adding another geometry to the plot.
We can use the `geom_smooth()` geometry to add a "regression line".

There are several methods available in `geom_smooth()`, but we can use the `"lm"` method to produce a regression line with confidence intervals based on a simple linear model `lm(y ~ x)` (we will talk about confidence intervals later in the course).

```{r art-int-plot-2, exercise=TRUE}
polite %>%
  ggplot(aes(...)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = ...) +
  labs(x = "Articulation rate (syll/s)", y = "Mean intensity (dB)")
```

```{r art-int-plot-2-hint}
geom_smooth(method = "lm")
```


```{r Q-art-int-plot}
question(
  "What does the plot suggest?",
  answer('The higher the articulation rate, the higher the intensity.'),
  answer('Mean intensity is the same across articulation rates.'),
  answer('Articulation rate and intensity are not correlated.', correct = TRUE),
  answer('Lower articulation rates correspond to lower intesity.'),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

### Does articulation rate correlates with intensity?

It is generally not enough to use plots to make inferences about data.
We need to model the data statistically as well.

Let's run a linear model with articulation rate `articulation_rate` as a predictor and mean intensity `inmn` as the outcome. 
Then check the model summary

```{r polite-lm, exercise=TRUE}
lm_2 <- ...

# Check the model summary
...
```

<div id="polite-lm-hint">
Remember to also specify the data with `data = `.
</div>

```{r Q-lm-2-1}
question(
  "Which of the following are correct?",
  answer('The average mean intensity is 62 dB when articulation rate is 0.', correct = TRUE),
  answer('The mean articulation rate is -0.01 syll/s.'),
  answer('The standard error of articulation rate is smaller that the estimate.'),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

```{r Q-lm-2-2}
question(
  "Which of the following is correct?",
  answer('Articulation rate is positively correlated with intensity.'),
  answer('For every increase of one syllable per second in articulation rate, there is a decrease of -0.01 dB in intensity.', correct = TRUE),
  answer('When intensity is 0, articulation rate is -0.01.'),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

```{r Q-lm-2-3}
question(
  "What is the mean intensity when articulation rate is 0??",
  answer('We cannot know from the model.'),
  answer('62 dB', correct = TRUE),
  answer('0 dB.'),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

### What is the takeaway?

Think about the following questions and answers in light of what you learnt from the course so far and from the model summary.

**Q**: What is the estimated effect of articulation rate on mean intensity?

**A**: The estimated effect of articulation rate on mean intensity is -0.01 dB.

---

**Q**: According to the model, what happens to mean intensity when articulation rate increases from 3 syll/s to 6 syll/s?

**A**: According to the model, when articulation rate increases from 3 syll/s to 6 syll/s, mean intensity goes from 61.956 dB to 61.922 dB.

---

**Q**: Does the model indicate a correlation between articulation rate and mean intensity?

**A**: The estimated effect of articulation rate on mean intensity is very small (-0.01 dB) considering the mean intensity is about 62 dB. We can say that the model suggest no correlation between articulation rate and intensity because the estimated effect is negligible.

## Example 3: Polish

### The Italian and Polish vowel duration data

The `dur_ita_pol` data frame contains data on vowel and consonant duration from speakers of Italian and Polish.

```{r dur, exercise=TRUE}
dur_ita_pol
```

### Consonant closure duration vs vowel duration

We want to investigate the relationship between consonant closure duration and vowel duration in VC sequences of CVCV nonce words produced by Polish speakers (we will ignore the Italian data).

In the chunk below, write code to do the following:

1. Filter the data so that you include only data from the Polish speakers.
2. Drop missing values of consonant closure duration `c2_clos_duration` (use the `drop_na()` function).
3. Make a scatter plot with `c2_clos_duration` and `v2_duration`.

```{r dur-plot, exercise=TRUE}
dur_ita_pol %>%
  ...
```

<div id="dur-plot-hint">
You can chain multiple commands using the pipe `%>%`.
</div>

### Are closure and vowel duration correlated?

Now time for a linear model!

Remember to filter the data and drop NAs as you did for the plot, but this time you have to save the output to `polish_data` so that you can use it in `lm()`.

Run a linear model with vowel duration as the outcome and consonant closure duration as the predictor.

```{r dur-lm, exercise=TRUE}
polish_data <- dur_ita_pol %>%
  filter(...) %>%
  drop_na(...)

lm_3 <- lm(..., data = polish_data)

summary(lm_3)
```

Excellent!

Now challenge yourself and think about the following questions. Can you answer them?

Feel free to share your answers and/or doubts on Piazza!

1. Does the model summary allow you to know which is the average vowel duration in the raw data?

2. Is the estimated effect of closure duration on vowel duration positive or negative? Why?

3. The interpretation of the estimated intercept (76.6 ms) is a bit counter-intuitive, because closure duration included in the model. Can you explain why?

4. If closure duration is 50 ms, which is the predicted duration of a vowel?


## Reporting

### You have being initiated to the world of linear modelling!

Hopefully you have now grasped the main basic aspects of linear models with a continuous predictor and a continuous outcome variable and you are now comfortable with interpreting the output of the model summaries.

But how would you go about reporting these models in a paper?
Nothing easier!

There is a standard way of reporting results from linear models.
The following sections will show you how each of the three models above can be reported.
Note that I tried to vary the way things are reported, but they are just all variations of the same standard approach to reporting.

For now we will only report estimates and standard errors, while we will include further information later on in the course.
In these examples I am being quite verbose, so in a real-world scenario you might want to strip reporting to a minimum, especially with more complex models (we will see examples later on).
Don't worry about any of this for the time being.

### Example 1

We fitted a linear model to reaction times, with Levenshtein distance as the only predictor.

The estimated intercept is 771 ms (SE = 24.85).
In other words, when Levenshtein distance is 0, the mean reaction time is 771 ms.
According to the model, Levenshtein distance increases reaction times by about 34 ms for each unit increase (SE = 3.45).

### Example 2

To investigate the effect of articulation rate on mean intensity, we ran a linear model with mean intensity as the outcome and articulation rate as the predictor.

Based on the model, the average intensity when articulation rate is 0 is about 62 dB (SE = 1.32).
For every increase of 1 syllable per second, intensity is lowered by -0.01 dB (SE = 0.19), which we interpret as being practically 0.
In summary, the model suggests that articulation rate does not affect mean intensity.

### Example 3

We fitted a linear model to investigate the relationship between consonanant closure duration and the duration of preceding vowels.

When closure duration is 0 ms, the expected duration of preceding vowels is about 77 ms (SE = 4.69).
For every 1 ms increase in closure duration, the predicted vowel duration decreases by -0.16 ms (SE = 0.07).
In other words, closure duration has a negative effect on vowel duration.
To illustrate the effect of closure duration, let' take a closure duration of 50 ms: according to the model, when closure duration is 50 ms, vowels are expected to be about 69 ms long.

### That's all folks (for now)!

Congratulations! You completed the third tutorial.

Now take a break and recharge, then keep calm and do what you do best.
