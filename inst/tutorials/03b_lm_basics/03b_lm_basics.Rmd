---
title: "SQM 03 - Linear Model Basics"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
library(sqmf)
library(tidyverse)
data("mald_1_1")
data("polite")
data("dur_ita_pol")
```

## Example 1: English

### The MALD data

We will use `mald_1_1` (made available through the sqmf package), which contains data from a lexical decision task.

We want to know if phoneme-level distance (`PhonLev`, i.e. Levenshtein distance) affect the reaction times of respondents when they need to decide whether the word they heard is a real word or a nonce word.

Here's what the data looks like.

```{r mald, exercise=TRUE}
mald_1_1
```

### Phoneme-level distance vs reaction times

Let's start by plotting phoneme-level distance (`PhonLev`) vs reaction times (`RT`).

You want to use a *scatter plot*.

```{r mald-plot, exercise=TRUE}
mald_1_1 %>%
  ...
```

<div id="mald-plot-hint">
A **scatter plot** is a plot with continuous variables in the *x* and *y* axes.
</div>

### Model distance vs RTs

Now we can run a simple linear model to investigate the relationship between phoneme-level distance and reaction times.

Fill in the following code with the right formula.

```{r mald-lm, exercise=TRUE}
lm_1 <- lm(..., data = mald_1_1)
```

And now look at the model summary!

```{r mald-summary-setup}
lm_1 <- lm(RT ~ PhonLev, data = mald_1_1)
```

```{r mald-summary, exercise=TRUE}
...
```

```{r mald-summary-hint}
summary(...)
```

### Does phoneme-level distance affect reaction times?

Great! Now that you have seen the model summary, answer the following questions.

```{r Q-lm-1-1, echo=FALSE}
question(
  "Which of the following statements is correct?",
  answer('The mean RT is 771.2 ms.'),
  answer('The model intercept is 33.7 ms.'),
  answer('When distance is 33.7, the average reaction time is 771.2 ms.'),
  answer('On average, the reaction time is 771.2 ms, when distance is 0.', correct = TRUE),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

```{r Q-lm-1-2, echo=FALSE}
question(
  "The effect of `PhonLev` on `RT` is",
  answer('positive.', correct = TRUE),
  answer('negative.'),
  answer('zero.'),
  answer('3.4 ms.'),
  correct = "Correct! The sign of the effect is `+`, so the effect is positive.",
  incorrect = "Nope!"
)
```

```{r Q-lm-1-3, echo=FALSE}
question(
  "Which of the following statements is correct?",
  answer('When the intercept is 0, phoneme-level distance is 33.7.'),
  answer('For every unit increase of phoneme-level distance, there is an increase of 33.7 ms.', correct = TRUE),
  answer('When phoneme-level distance is 0, the reaction time is 33.7 ms.'),
  answer('For every 1 ms, the phoneme-level distance increases by 33.7.'),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

```{r Q-lm-1-4, echo=FALSE}
question(
  "What is the effect of phoneme-level distance when the distance is 3?",
  answer('101.1 ms.', correct = TRUE),
  answer('0 ms.'),
  answer('33.7 ms.'),
  answer('3.4 ms.'),
  correct = "Correct! To get the effect when distance is 3, you just do `33.7 * 3`.",
  incorrect = "Nope!"
)
```

## Example 2: Korean

### The politness data

Let's move now to `polite` (made available through the sqmf package), which contains data from study of the acoustics of polite speech in Korean.

Imagine we want to know, regardless of attitude (i.e. informal vs polite speech), if articulation rate (i.e. the number of syllables per second) is correlated with the mean intensity of each utterance.

Here's what the data looks like.

```{r polite, exercise=TRUE}
polite
```

### Articulation rate vs intensity

Let's make a plot of articulation rate vs intensity.

```{r art-int-plot-1, exercise=TRUE}
polite %>%
  ggplot(aes(...)) +
  geom_point() +
  labs(x = "Articulation rate (syll/s)", y = "Mean intensity (dB)")
```

Does it look like there is something about articulation rate and intensity?

Let's further check by adding another geometry to the plot.
We can use the `geom_smooth()` geometry to add a "regression line".

There are several methods available in `geom_smooth()`, but we can use the `"lm"` method to produce a regression line with confidence intervals based on a simple linear model `lm(y ~ x)` (we will talk about confidence intervals later in the course).

```{r art-int-plot-2, exercise=TRUE}
polite %>%
  ggplot(aes(...)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = ...) +
  labs(x = "Articulation rate (syll/s)", y = "Mean intensity (dB)")
```


```{r Q-art-int-plot}
question(
  "What does the plot suggest?",
  answer('The higher the articulation rate, the higher the intensity.'),
  answer('Mean intensity is the same across articulation rates.'),
  answer('Articulation rate and intensity are not correlated.', correct = TRUE),
  answer('Lower articulation rates correspond to lower intesity.'),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

### Does articulation rate correlates with intensity?

It is generally not enough to use plots to make inferences about data.
We need to model the data statistically as well.

Let's run a linear model with articulation rate `articulation_rate` as a predictor and mean intensity `inmn` as the outcome. 
Then check the model summary

```{r polite-lm, exercise=TRUE}
lm_2 <- ...

# Check the model summary
...
```

<div id="polite-lm-hint">
Remember to also specify the data with `data = `.
</div>

```{r Q-lm-2-1}
question(
  "Which of the following are correct?",
  answer('The average mean intensity is 62 dB.', correct = TRUE),
  answer('The mean articulation rate is -0.01 syll/s.'),
  answer('The standard error of articulation rate is smaller that the estimate.'),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

```{r Q-lm-2-2}
question(
  "Which of the following is correct?",
  answer('Articulation rate is positively correlated with intensity.'),
  answer('For every increase of one syllable per second in articulation rate, there is a decrease of -0.01 dB in intensity.', correct = TRUE),
  answer('When intensity is 0, articulation rate is -0.01.'),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

```{r Q-lm-2-3}
question(
  "What is the mean intensity when articulation rate is 0??",
  answer('We cannot know from the model.'),
  answer('62 dB', correct = TRUE),
  answer('0 dB.'),
  correct = "Correct!",
  incorrect = "Nope!"
)
```

### What is the takeaway?

Think about the following questions and answers in light of what you learnt from the course so far and from the model summary.

**Q**: What is the estimated effect of articulation rate on mean intensity?

**A**: The estimated effect of articulation rate on mean intensity is -0.01 dB.

---

**Q**: According to the model, what happens to mean intensity when articulation rate increases from 3 syll/s to 6 syll/s?

**A**: According to the model, when articulation rate increases from 3 syll/s to 6 syll/s, mean intensity goes from 61.956 dB to 61.922 dB.

---

**Q**: Does the model indicate a correlation between articulation rate and mean intensity?

**A**: The estimated effect of articulation rate on mean intensity is very small (-0.01 dB) considering the mean intensity is about 62 dB. We can say that the model suggest no correlation between articulation rate and intensity because the estimated effect is negligible.

## Example 3: Polish

### The Italian and Polish vowel duration data

The `dur_ita_pol` data frame contains data on vowel and consonant duration from speakers of Italian and Polish.

```{r dur, exercise=TRUE}
dur_ita_pol
```

### Consonant closure duration vs vowel duration

We want to investigate the relationship between consonant closure duration and vowel duration in VC sequences of CVCV nonce words produced by Polish speakers (we will ignore the Italian data).

In the chunk below, write code to do the following:

1. Filter the data so that you include only data from the Polish speakers.
2. Drop missing values of consonant closure duration `c2_clos_duration` (use the `drop_na()` function).
3. Make a scatter plot with `c2_clos_duration` and `v2_duration`.

```{r dur-plot, exercise=TRUE}
dur_ita_pol %>%
  ...
```

<div id="dur-plot-hint">
You can chain multiple commands using the pipe `%>%`.
</div>

### Are closure and vowel duration correlated?

Now time for a linear model!

Remember to filter the data and drop NAs as you did for the plot, but this time you have to save the output to `polish_data` so that you can use it in `lm()`.

Run a linear model with vowel duration as the outcome and consonant closure duration as the predictor.

```{r dur-lm, exercise=TRUE}
polish_data <- dur_ita_pol %>%
  filter(...) %>%
  drop_na(...)

lm_3 <- lm(..., data = polish_data)

summary(lm_3)
```

Excellent!

Now challenge yourself and think about the following questions. Can you answer them?

Feel free to share your answers and/or doubts on Piazza!

1. Is it possible to tell, just by looking at the model summary, which is the average vowel duration in the data?

2. Is the estimated effect of closure duration on vowel duration positive or negative? Why?

3. Interpreting the estimated intercept (76.6 ms) is counterintuitive, because in this model closure duration is measured as syllables per second. Can you explain why?

4. If closure duration is 50 ms, which is the predicted duration of a vowel?
