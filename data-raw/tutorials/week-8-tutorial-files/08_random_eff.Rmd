---
title: "08 - Linear models: Hierarchical data"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = here::here())
library(tidyverse)
library(ggeffects)
library(broom.mixed)
```

# Exercise 1

## Read the data

For this tutorial will be using data on Mancunian English vowel duration.

The data in fact comes with two files:

- `english-durations.csv` which contains vowel duration and trial info.
- `stimuli.csv` which contains info on the stimuli.

In order to analyse the data we need to join these two tables into one.
This is what the *join* operations from the tidyverse are for!

First, let's read both data tables individually.
Fill in the code below.

**Note** that the `english-duration.csv` file was generated by Praat which uses by default "--undefined--" for NA values.
To correctly read the file you need to manually specify which strings will be  read as NA, using the `na` argument of `read_csv()`.
Check the documentation with `?read_csv()` to learn how to use this argument.

```{r read}
eng_dur <- ...
stimuli <- ...
```

Inspect the data frames.
You will see that both data frames have a column called `sentence`.
We can use this column to join the `stimuli` data frame with the `eng_dur` data frame.

You will also have noticed that `eng_dur` has 1800 observations, while `stimuli` has only 120.

```{r dims}
# Returns nrow and ncol
dim(eng_dur)
dim(stimuli)
```

So what is going on?

Basically, `stimuli` contains information on the stimuli used in the study.
If you check the individual sentence stimuli in `eng_dur` you will see that these are 120.

```{r sents}
length(unique(eng_dur$sentence))
```

What we want to do is to join `stimuli` so that for each occurrence of a sentence stimulus in `eng_dur` we get information on the stimulus added as extra columns taken from `stimuli`.

## Join the data

We can achieve this using `left_join()` (`full_join()` would also work, but to avoid complicating things, let's stick to `left_join()`. If you want to know more, check the documentation: <https://dplyr.tidyverse.org/reference/mutate-joins.html>).

The function `left_join()` takes two data frames and joins them based on common columns.
Since in our case the only shared column in `sentence`, the function will use that column to join the data frames.

```{r join}
eng_dur_j <- left_join(eng_dur, stimuli)
```

You see that R alerts you that it's joining by `sentence`.

Check out the new joined data frame now:

```{r eng-dur-j}
eng_dur_j
```

Now `eng_dur_j` has columns from both `eng_dur` and `stimuli`!

## Prep the data

Let's assume we are interested in investigating vowel duration in Mancunian English.

The data contains vowel duration measurements from 15 speakers...

```{r n-speakers}
length(unique(eng_dur_j$speaker))
```

and from 24 nonce words.

```{r n-words}
length(unique(eng_dur_j$word))
```

The words can be grouped by number of syllables, vowel and voicing of the consonant following the vowel.

```{r words}
# table() is the R base equivalent of using `count()`
table(eng_dur_j$vowel, eng_dur_j$voicing, eng_dur_j$num_syl)
```

```{r words-2}
# Same info as above
eng_dur_j %>%
  count(num_syl, vowel, voicing)
```

More specifically, we want to assess the effect of voicing on vowel duration, depending on the vowel quality (ee, er, ar) and whether the word is monosyllabic or disyllabic, while controlling for speech rate.

Before moving on to the linear model, mutate the data so that:

- `num_syl` is a factor with levels ordered as `mono` and `di`.
- `vowel` is a factor with levels ordered as `ee`, `er`, `ar`.
- `voicing` is a factor with levels ordered as `voiceless` and `voiced`.
- `vow_dur` is the duration of the vowel in ms.
- `sent_syl` contains the number of syllables in the sentence stimuli. You can achieve this using `ifelse()` and `num_syl`: when the word is monosyllabic, the sentence has 6 syllables, when disyllabic the sentence has 7.
- `sentence_dur` is the duration of each sentence.
- Calculate `speech_rate` so that it is number of syllables in the sentence per second.
- Then centre `speech_rate`.

```{r mutate}
...
```



## Run a linear model with random effects

Repeating from above, we want to assess the effect of voicing on vowel duration, depending on the vowel quality (ee, er, ar) and whether the word is monosyllabic or disyllabic.

This screams **INTERACTIONS!!!**. Do you see why?

Now go ahead and run a linear model with vowel duration as the outcome. Which family should you use?

Include `vowel`, `voicing`, `num_syl` and their interactions, plus centred `speech_rate` as fixed effects.
You want to include `speaker` as a varying intercept and you also want to add varying slopes for `vowel`, `voicing`, `num_syl`.
Remember to use the `g/lmer()` function from the lme4 package since you are including random effects.

Are you fine with treatment coding of the categorical predictors? Should you use sum coding maybe?
There is no correct answer.

```{r eng-dur-lm}
...
```

Get predictions and plot them.

```{r eng-dur-lm-preds}

```

And now write up the model specification and results.






# Exercise 2

Pick any of the data we have used so far that has multiple subjects and/or items/words and run a linear model including random effects.
Get predictions and make plots with `ggpredict()`.
Write up the model specification and results.

